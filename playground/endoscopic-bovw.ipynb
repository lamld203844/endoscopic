{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Base"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T10:22:46.983003Z","iopub.status.busy":"2024-09-29T10:22:46.982563Z","iopub.status.idle":"2024-09-29T10:22:49.642771Z","shell.execute_reply":"2024-09-29T10:22:49.641517Z","shell.execute_reply.started":"2024-09-29T10:22:46.982944Z"},"trusted":true},"outputs":[],"source":["import os\n","from collections import Counter\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from PIL import Image\n","import cv2\n","\n","import joblib\n","from sklearn.cluster import KMeans\n","from scipy.cluster.vq import vq\n","\n","np.random.seed(0)  # reproducibility"]},{"cell_type":"markdown","metadata":{},"source":["# BoVW class"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T10:53:42.629546Z","iopub.status.busy":"2024-09-29T10:53:42.629114Z","iopub.status.idle":"2024-09-29T10:53:42.653049Z","shell.execute_reply":"2024-09-29T10:53:42.651648Z","shell.execute_reply.started":"2024-09-29T10:53:42.629507Z"},"trusted":true},"outputs":[],"source":["class BagOfVisualWords:\n","    def __init__(\n","        self,\n","        root_dir: str = \"/kaggle/input/the-hyper-kvasir-dataset/labeled_images\",\n","        all_descriptors_dir: str = None,\n","        codebook_dir: str = None,\n","    ):\n","        \"\"\"Constructor method\n","        \n","        :param all_descriptors_dir: str (optional), path to file including all computed descriptors (vectors)\n","        :param codebook_dir: str (optional), path to visual vocabulary\n","        \n","        \"\"\"\n","        self.root_dir = root_dir\n","        self.df = pd.read_csv(f\"{root_dir}/image-labels.csv\")\n","        self.labels = tuple(self.df[\"Finding\"].unique())\n","        \n","        # n descriptors of m images extracted from given extractor (description algorithm/ feature detection)\n","        if all_descriptors_dir is not None:\n","            self.all_descriptors = joblib.load(all_descriptors_dir)\n","        \n","        # codebook (Lookup table)\n","        if codebook_dir is not None:\n","            self.k, self.codebook = joblib.load(codebook_dir)\n","        \n","        # In reality in building codebook, choose small sample size idx for efficient \n","        self.samples_idx = []  \n","\n","    def extract_descriptors(self, method: str = 'sift',\n","                                sample_size: int = 2000,\n","                                grayscale: bool = True,\n","                                strongest_percent: float = 1,\n","                                **extractor_kwargs\n","                        ) -> np.array:\n","        \"\"\"Extract descriptors from sample_size images\n","        :param method: str, method to extract feature descriptors e.g. ORB, SIFT, SURF, etc\n","        :param sample_size: size of sample. (We likely use a small sample in real-world scenario,\n","            where whole dataset is big)\n","        :param grayscale: bool - if True, convert to gray for efficient computing\n","        :param strongest_percent: float - get % percent of strongest (based on .response of keypoints)\n","        descriptors.  \n","\n","        :return: list, n descriptors x sample_size images\n","        \n","        # TODO: sample for building visual vocabulary must be balance between classes\n","        every class include at least one image\n","        \"\"\"\n","        # ------ extracting algorithms --------\n","        self.method = method\n","        if method == \"sift\":\n","            self.extractor = cv2.SIFT_create(**extractor_kwargs)\n","        elif method == \"orb\":\n","            self.extractor = cv2.ORB_create(**extractor_kwargs)\n","        elif method == \"surf\":\n","            self.extractor = cv2.xfeatures2d.SURF_create(**extractor_kwargs)\n","        else:\n","            raise ValueError(f\"Unsupported feature extracting method: {method}\")\n","        \n","        # ----- extracting process -------\n","        # == Sampling ==\n","        self.sample_idx = np.random.choice(np.arange(0, len(self.df)),\n","                                            size=sample_size,\n","                                            replace=False\n","                                        ).tolist() #  randomly sample sample_size images\n","\n","        descriptors_sample_all = (\n","            []\n","        )  # each image has many descriptors, descriptors_sample_all\n","        # is a list of all descriptors of sample_size images\n","\n","        # loop each image > extract > append\n","        for idx in self.sample_idx:\n","            img, _ = self._get_item(idx)\n","            # convert to grayscale for efficient computing\n","            if len(img.shape) == 3 and grayscale:\n","                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","            # descriptors extracting\n","            img_keypoints, img_descriptors = self.extractor.detectAndCompute(img, None)\n","            if img_descriptors is not None:\n","                # filter top_percent strongest keypoint\n","                sorted_couple = sorted(zip(img_keypoints, img_descriptors), key=lambda x: x[0].response, reverse=True)\n","                img_keypoints, img_descriptors = zip(*sorted_couple) # unzip\n","                top = int(len(img_keypoints) * strongest_percent)\n","                top_descriptors = img_descriptors[:top]               \n","                \n","                for descriptor in top_descriptors:\n","                    descriptors_sample_all.append(np.array(descriptor))\n","\n","        # convert to single numpy array\n","        descriptors_sample_all = np.stack(descriptors_sample_all)\n","\n","        return descriptors_sample_all\n","\n","    def build_codebook(\n","        self,\n","        all_descriptors: np.array,\n","        cluster_algorithm: str = 'kmean',\n","        k: int = 200,\n","    ) -> np.array:\n","        \"\"\"Building visual vocabulary (visual words)\n","        :param all_descriptors: array of descriptors\n","        :param cluster_algorithm: type of cluster algorithm like K-mean, Birch\n","        :param k: #cluster (centroids)\n","        \n","        :return: #centroids, codebook\n","\n","        \"\"\"\n","        kmeans = KMeans(n_clusters=k, random_state=123)\n","        kmeans.fit(all_descriptors)\n","\n","        return kmeans.cluster_centers_\n","\n","    def get_embedding(self, idx: int, normalized: bool = False, tfidf: bool = False):\n","        \"\"\"Get embeddings of image[idx] (image > descriptors > project in codebook > frequencies vectors)\n","        :param idx: int, image index\n","        :param normalized: bool, if True, normalize embedding in scale [0, 1]\n","\n","        :return: np.array, frequencies vector (can consider as embedding)\n","        \"\"\"\n","        img_descriptors = self._get_descriptors_one_img(idx)\n","        img_visual_words, distance = vq(img_descriptors, self.codebook)\n","        img_frequency_vector = np.histogram(\n","            img_visual_words, bins=self.k, density=normalized\n","        )[0]\n","\n","        if tfidf:\n","            self._tf_idf()\n","            img_frequency_vector = img_frequency_vector * self.idf\n","\n","        return img_frequency_vector\n","\n","    def _tf_idf(self):\n","        \"\"\"TODO: Reweight important features in codebook\"\"\"\n","        self.idf = 1\n","\n","        all_embeddings = []\n","        for i in range(len(self.df)):\n","            embedding = self.get_embedding(i)\n","            all_embeddings.append(embedding)\n","\n","        all_embeddings = np.stack(all_embeddings)\n","\n","        N = len(self.df)\n","        df = np.sum(all_embeddings > 0, axis=0)\n","        idf = np.log(N / df)\n","\n","        return idf\n","\n","    def _get_item(self, idx) -> tuple:\n","        \"\"\"Return pair (image(arr), label)\n","        :param idx: index of data\n","\n","        :return: tuple, (image: np.array, label)\n","        \"\"\"\n","        # get path of image\n","        GI_dir = {\"Lower GI\": \"lower-gi-tract\", \"Upper GI\": \"upper-gi-tract\"}\n","\n","        img = self.df[\"Video file\"][idx]\n","        gi_tract = GI_dir[self.df[\"Organ\"][idx]]\n","        classification = self.df[\"Classification\"][idx]\n","        finding = self.df[\"Finding\"][idx]\n","        path = f\"\"\"{self.root_dir}/{gi_tract}/{classification}/{finding}/{img}.jpg\"\"\"\n","        assert (\n","            os.path.exists(path) == True\n","        ), f\"{path} does not exist\"  # dir existance checking\n","\n","        # read image\n","        image = np.array(Image.open(path))\n","        label = self.labels.index(finding)\n","\n","        return image, label\n","    \n","    def _get_descriptors_one_img(self, idx, grayscale=True):\n","        \"\"\"Extracting descriptors for each image[idx]\n","        :param method: method to extract features e.g. ORB, SIFT, SURF, etc\n","        :param idx: image index\n","\n","        :return: descriptors\n","        :rtype: np.array\n","        \"\"\"\n","        # get image\n","        img, _ = self._get_item(idx)\n","        # preprocessing: convert to grayscale for efficient computing\n","        if len(img.shape) == 3 and grayscale:\n","            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","        # descriptors extracting\n","        _, img_descriptors = self.extractor.detectAndCompute(img, None)\n","\n","        return img_descriptors"]},{"cell_type":"markdown","metadata":{},"source":["# Pipeline"]},{"cell_type":"markdown","metadata":{},"source":["## 1. extracting descriptors"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["==================== Completely extracting descriptors ====================\n"]}],"source":["model = BagOfVisualWords(\n","        root_dir=\"/media/mountHDD2/lamluuduc/endoscopy/dataset/hyperKvasir/labeled-images\",\n","#         codebook_dir=\"/kaggle/input/bag-of-visual-words/bovw_codebook_sift.pkl\",\n","    )\n","# ----- 1. extracting descriptors -------------\n","'''hyperparameters'''\n","method = 'sift'\n","sample_size = len(model.df) # test\n","strongest_percent = 1\n","'''hyperparameters'''\n","\n","all_descriptors = model.extract_descriptors(method=method,\n","                                            sample_size=sample_size,\n","                                            strongest_percent=strongest_percent)\n","\n","# == saving all descriptors ==\n","ckpt_path = '../checkpoints'\n","# name convention for saving sample_size-method-strongest.pkl\n","all_descriptors_path = joblib.dump(all_descriptors,\n","                                    f'{ckpt_path}/descriptors/{sample_size}_img-{model.method}_extractor-{strongest_percent*100}%_strongest.pkl',\n","                                    compress=3)\n","print('='*20, 'Completely extracting descriptors', '='*20)"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Building codebook"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 10568760/10568760 [00:01<00:00, 7530680.87it/s]\n"]}],"source":["from tqdm import tqdm\n","a = np.arange(0, 10, 1)\n","for i in tqdm(range(0, len(all_descriptors))):\n","    ..."]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T10:55:24.734426Z","iopub.status.busy":"2024-09-29T10:55:24.733839Z","iopub.status.idle":"2024-09-29T10:55:29.705982Z","shell.execute_reply":"2024-09-29T10:55:29.704870Z","shell.execute_reply.started":"2024-09-29T10:55:24.734371Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Video file</th>\n","      <th>Organ</th>\n","      <th>Finding</th>\n","      <th>Classification</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000e3fee-7f5c-4819-9f9c-4c983b68888a</td>\n","      <td>Lower GI</td>\n","      <td>cecum</td>\n","      <td>anatomical-landmarks</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>001a41c2-2a5d-40b1-8fd5-b5f2f292277b</td>\n","      <td>Lower GI</td>\n","      <td>cecum</td>\n","      <td>anatomical-landmarks</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>006af0aa-2044-4477-964d-10d9e043fb78</td>\n","      <td>Lower GI</td>\n","      <td>cecum</td>\n","      <td>anatomical-landmarks</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00832522-ab8e-4b98-bfce-93a777929571</td>\n","      <td>Lower GI</td>\n","      <td>cecum</td>\n","      <td>anatomical-landmarks</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>012ab888-64e6-4361-9745-f52b4a03ba75</td>\n","      <td>Lower GI</td>\n","      <td>cecum</td>\n","      <td>anatomical-landmarks</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>10657</th>\n","      <td>f7dd198b-88f0-4566-b8f4-81c8c2fee1ed</td>\n","      <td>Upper GI</td>\n","      <td>esophagitis-b-d</td>\n","      <td>pathological-findings</td>\n","    </tr>\n","    <tr>\n","      <th>10658</th>\n","      <td>f9a06ca3-3500-4e5e-ac46-110b52963a99</td>\n","      <td>Upper GI</td>\n","      <td>esophagitis-b-d</td>\n","      <td>pathological-findings</td>\n","    </tr>\n","    <tr>\n","      <th>10659</th>\n","      <td>fb31e2c2-c8db-42b3-bbf1-564e42076a8e</td>\n","      <td>Upper GI</td>\n","      <td>esophagitis-b-d</td>\n","      <td>pathological-findings</td>\n","    </tr>\n","    <tr>\n","      <th>10660</th>\n","      <td>fe6c191e-3da0-4f18-9e38-8f7a11097a3b</td>\n","      <td>Upper GI</td>\n","      <td>esophagitis-b-d</td>\n","      <td>pathological-findings</td>\n","    </tr>\n","    <tr>\n","      <th>10661</th>\n","      <td>ff4f2ed2-69a8-455d-894a-8d536b324653</td>\n","      <td>Upper GI</td>\n","      <td>esophagitis-b-d</td>\n","      <td>pathological-findings</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10662 rows × 4 columns</p>\n","</div>"],"text/plain":["                                 Video file     Organ          Finding  \\\n","0      000e3fee-7f5c-4819-9f9c-4c983b68888a  Lower GI            cecum   \n","1      001a41c2-2a5d-40b1-8fd5-b5f2f292277b  Lower GI            cecum   \n","2      006af0aa-2044-4477-964d-10d9e043fb78  Lower GI            cecum   \n","3      00832522-ab8e-4b98-bfce-93a777929571  Lower GI            cecum   \n","4      012ab888-64e6-4361-9745-f52b4a03ba75  Lower GI            cecum   \n","...                                     ...       ...              ...   \n","10657  f7dd198b-88f0-4566-b8f4-81c8c2fee1ed  Upper GI  esophagitis-b-d   \n","10658  f9a06ca3-3500-4e5e-ac46-110b52963a99  Upper GI  esophagitis-b-d   \n","10659  fb31e2c2-c8db-42b3-bbf1-564e42076a8e  Upper GI  esophagitis-b-d   \n","10660  fe6c191e-3da0-4f18-9e38-8f7a11097a3b  Upper GI  esophagitis-b-d   \n","10661  ff4f2ed2-69a8-455d-894a-8d536b324653  Upper GI  esophagitis-b-d   \n","\n","              Classification  \n","0       anatomical-landmarks  \n","1       anatomical-landmarks  \n","2       anatomical-landmarks  \n","3       anatomical-landmarks  \n","4       anatomical-landmarks  \n","...                      ...  \n","10657  pathological-findings  \n","10658  pathological-findings  \n","10659  pathological-findings  \n","10660  pathological-findings  \n","10661  pathological-findings  \n","\n","[10662 rows x 4 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# ------- 2. building visual vocabulary -----------\n","'''hyperparameters'''\n","k = 200 # #cluster = vector size\n","cluster_algorithm='kmean'\n","'''hyperparameters'''\n","all_descriptors = joblib.load(*all_descriptors_path) # unpack list (result from joblib.dump())\n","codebook = model.build_codebook(all_descriptors=all_descriptors,\n","                                    cluster_algorithm='kmean',\n","                                    k=200\n","                                )\n","print('='*20, '\\nCompletely building codebook', '='*20)\n","codebook.shape\n","codebook = model.build_codebook(all_descriptors, k)\n","joblib.dump((k, codebook), f'bovw_codebook_{model.method}.pkl', compress=3) # saving codebook\n","\n","embedding = model.get_embedding(0, normalized=True)\n","plt.bar(list(range(len(embedding))),embedding)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-03T16:11:59.806281Z","iopub.status.busy":"2024-09-03T16:11:59.805874Z","iopub.status.idle":"2024-09-03T16:11:59.986952Z","shell.execute_reply":"2024-09-03T16:11:59.985825Z","shell.execute_reply.started":"2024-09-03T16:11:59.806243Z"},"trusted":true},"outputs":[],"source":["headers = [f'feature{i}' for i in range(model.k)]\n","embedding_df = pd.DataFrame(columns=headers)\n","labels = []\n","\n","# Embedding entire dataset\n","for idx in range(len(model.df)):\n","    img, label = model._get_item(idx)\n","    embedding = model.get_embedding(idx, normalized=True)\n","    # Add a row to the DataFrame\n","    embedding_df.loc[len(embedding_df)] = embedding\n","    labels.append(label)\n","#     break\n","\n","embedding_df['label'] = pd.Series(labels, dtype='int')\n","\n","embedding_df.to_csv('embeddings_with_labels.csv', index=False)\n","\n","# embedding_df"]},{"cell_type":"markdown","metadata":{},"source":["# Classification with embeddings"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T04:31:55.149002Z","iopub.status.busy":"2024-09-11T04:31:55.148366Z","iopub.status.idle":"2024-09-11T04:31:56.109387Z","shell.execute_reply":"2024-09-11T04:31:56.108194Z","shell.execute_reply.started":"2024-09-11T04:31:55.148954Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","# 1. Load dataset\n","df = pd.read_csv('/kaggle/input/bag-of-visual-words/embeddings_with_labels.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T04:32:05.307086Z","iopub.status.busy":"2024-09-11T04:32:05.306437Z","iopub.status.idle":"2024-09-11T04:32:20.301552Z","shell.execute_reply":"2024-09-11T04:32:20.299951Z","shell.execute_reply.started":"2024-09-11T04:32:05.307031Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 58.51%\n"]}],"source":["# 2. Extract features, labels\n","X = df.iloc[:, 0:200]\n","y = df.iloc[:, 200]\n","\n","# Step 3: Divide the dataset into training and testing sets (80% training, 20% testing)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Step 4: Train a basic model (Random Forest Classifier in this case)\n","model = RandomForestClassifier(random_state=42)\n","model.fit(X_train, y_train)\n","\n","# Step 5: Predict on the test set\n","y_pred = model.predict(X_test)\n","\n","# Step 6: Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy * 100:.2f}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T04:32:20.303851Z","iopub.status.busy":"2024-09-11T04:32:20.303431Z"},"trusted":true},"outputs":[],"source":["# Step 7: Perform cross-validation\n","cv_scores = cross_val_score(model, X, y, cv=5)  # 5-fold cross-validation\n","print(f'Cross-validation Accuracy: {cv_scores.mean() * 100:.2f}%')\n"]},{"cell_type":"markdown","metadata":{},"source":["# Test"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-08T15:45:33.205529Z","iopub.status.busy":"2024-09-08T15:45:33.204945Z","iopub.status.idle":"2024-09-08T15:45:33.524331Z","shell.execute_reply":"2024-09-08T15:45:33.523152Z","shell.execute_reply.started":"2024-09-08T15:45:33.205467Z"},"trusted":true},"outputs":[],"source":["\n","# =========== Sanity check =================================\n","# ====================== Unit tests =================================================\n","def test_attributes():\n","    assert model.df.shape == (10662, 4)  # dataframe\n","    assert len(model.labels) == 23  # #labels\n","\n","\n","# test _get_item method\n","def test_get_item():\n","    image, label = model._get_item(0)\n","    assert len(image.shape) == 3  # image is a 3-dimensional array (h, w, c)\n","    assert type(label) == int and 0 <= label <= 22  # label\n","\n","\n","# test _get_descriptors method\n","def test_get_descriptors():\n","    img_descriptors = model._get_descriptors(0)\n","    assert len(img_descriptors.shape) == 2\n","\n","\n","# test extract all descriptors process method\n","def test_extract_desciptors():\n","    # all_descriptors = model.extract_descriptors() # ensure output is 2d\n","    assert len(model.all_descriptors.shape) == 2, \"Invalid extracting process\"\n","    # assert len(model.sample_idx) == 1000, 'Invalid sampling'\n","\n","\n","# test build_codebook method\n","def test_build_codebook():\n","    assert model.codebook.shape == (model.k, 128), \"Invalid building codebook process\"\n","\n","\n","# test get_embedding method\n","def test_get_embedding():\n","    embedding = model.get_embedding(0)\n","    assert embedding.shape[0] == model.k\n","    \n","test_attributes()\n","test_get_item()\n","test_get_descriptors()\n","# test_extract_desciptors()\n","test_build_codebook()\n","test_get_embedding()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":1150130,"sourceId":1928154,"sourceType":"datasetVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
