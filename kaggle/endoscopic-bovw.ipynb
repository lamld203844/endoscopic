{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Base"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T08:41:38.308013Z","iopub.status.busy":"2024-10-19T08:41:38.307516Z","iopub.status.idle":"2024-10-19T08:41:38.316857Z","shell.execute_reply":"2024-10-19T08:41:38.315832Z","shell.execute_reply.started":"2024-10-19T08:41:38.307972Z"},"trusted":true},"outputs":[],"source":["import os\n","from collections import Counter\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from tqdm import tqdm\n","from PIL import Image\n","import cv2\n","import joblib\n","\n","from sklearn.cluster import KMeans, MiniBatchKMeans\n","from scipy.cluster.vq import vq\n","\n","np.random.seed(0)  # reproducibility\n","root_dir = '/teamspace/studios/this_studio/dataset/labeled-images'\n","ckpt_path = './checkpoints'\n","\n","os.makedirs(ckpt_path, exist_ok=True)\n","os.makedirs(f'{ckpt_path}/descriptors/', exist_ok=True)\n","os.makedirs(f'{ckpt_path}/codebook/', exist_ok=True)\n","os.makedirs(f'{ckpt_path}/embedding_df/', exist_ok=True)\n","\n","s_id = np.random.randint(0, 100)"]},{"cell_type":"markdown","metadata":{},"source":["# BoVW class"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T10:09:23.165626Z","iopub.status.busy":"2024-10-19T10:09:23.164859Z","iopub.status.idle":"2024-10-19T10:09:23.190461Z","shell.execute_reply":"2024-10-19T10:09:23.189298Z","shell.execute_reply.started":"2024-10-19T10:09:23.165576Z"},"trusted":true},"outputs":[],"source":["from typing import Optional\n","\n","class BagOfVisualWords:\n","    def __init__(\n","        self,\n","        root_dir: str = \"/kaggle/input/the-hyper-kvasir-dataset/labeled_images\",\n","        descriptors_lake_path: str = None,\n","        codebook_dir: str = None,\n","        \n","        method: str = 'sift',\n","        extractor_kwargs: dict = None,\n","    ):\n","        \"\"\"Constructor method\n","        \n","        :param descriptors_lake_path: str (optional), path to file including all computed descriptors (vectors)\n","        :param codebook_dir: str (optional), path to visual vocabulary\n","        \n","        \"\"\"\n","        self.root_dir = root_dir\n","        self.df = pd.read_csv(f\"{root_dir}/image-labels.csv\")\n","        self.labels = tuple(self.df[\"Finding\"].unique())\n","        \n","        # In reality in building codebook, choose small sample size idx for efficient \n","        self.samples_idx = []  \n","\n","        # ------ extracting algorithms --------\n","        self.method = method\n","        if method == \"sift\":\n","            self.extractor = cv2.SIFT_create()\n","        elif method == \"orb\":\n","            self.extractor = cv2.ORB_create(**extractor_kwargs)\n","        elif method == \"surf\":\n","            self.extractor = cv2.xfeatures2d.SURF_create(**extractor_kwargs)\n","        else:\n","            raise ValueError(f\"Unsupported feature extracting method: {method}\")\n","            \n","    def extract_descriptors(self, sample_size: int = 2000,\n","                                grayscale: bool = True,\n","                                strongest_percent: float = 1,\n","                                **extractor_kwargs\n","                        ) -> np.array:\n","        \"\"\"Extract descriptors from sample_size images\n","        :param method: str, method to extract feature descriptors e.g. ORB, SIFT, SURF, etc\n","        :param sample_size: size of sample. (We likely use a small sample in real-world scenario,\n","            where whole dataset is big)\n","        :param grayscale: bool - if True, convert to gray for efficient computing\n","        :param strongest_percent: float - get % percent of strongest (based on .response of keypoints)\n","        descriptors.  \n","\n","        :return: list, n descriptors x sample_size images\n","\n","        # TODO: sample for building visual vocabulary must be balance between classes\n","        every class include at least one image\n","        \"\"\"\n","        # ------- Sampling -----------\n","        self.sample_idx = np.random.choice(np.arange(0, len(self.df)),\n","                                            size=sample_size,\n","                                            replace=False\n","                                        ).tolist() #  randomly sample sample_size images\n","\n","        descriptors_sample_all = (\n","            []\n","        )  # each image has many descriptors, descriptors_sample_all\n","        # is a list of all descriptors of sample_size images\n","\n","        # loop each image > extract > append\n","        for idx in tqdm(self.sample_idx):\n","            img_keypoints, img_descriptors = self._get_descriptors_one_img(idx)\n","            if img_descriptors is not None:\n","                # filter top_percent strongest keypoint\n","                sorted_couple = sorted(zip(img_keypoints, img_descriptors), key=lambda x: x[0].response, reverse=True)\n","                img_keypoints, img_descriptors = zip(*sorted_couple) # unzip\n","                top = int(len(img_keypoints) * strongest_percent)\n","                top_descriptors = img_descriptors[:top]               \n","\n","                for descriptor in top_descriptors:\n","                    descriptors_sample_all.append(np.array(descriptor))\n","\n","        # convert to single numpy array\n","        descriptors_sample_all = np.stack(descriptors_sample_all)\n","\n","        return descriptors_sample_all\n","\n","    def build_codebook(\n","        self,\n","        descriptors_lake: np.array,\n","        cluster_algorithm: str = 'kmean',\n","        k: int = 200,\n","        batch_size = 1000,\n","        n_init: int = 10\n","    ) -> np.array:\n","        \"\"\"Building visual vocabulary (visual words)\n","        :param descriptors_lake: array of descriptors\n","        :param cluster_algorithm: type of cluster algorithm like K-mean, Birch\n","        :param k: #cluster (centroids)\n","        \n","        :return: #centroids, codebook\n","\n","        \"\"\"\n","        if cluster_algorithm == 'kmean':\n","            cluster_model = MiniBatchKMeans(n_clusters=k,\n","                                            batch_size=batch_size,\n","                                            random_state=123,\n","                                            n_init=n_init)\n","\n","        # n_batches = int(len(descriptors_lake) / batch_size)\n","        for _ in tqdm(range(n_init), desc='Initializing'):\n","            cluster_model.partial_fit(descriptors_lake)\n","\n","        # Final clustering\n","        cluster_model.fit(descriptors_lake)\n","        return cluster_model.cluster_centers_\n","    \n","    # ------------------------ for inference ----------------------------\n","    def get_embedding(\n","        self,\n","        idx: int,\n","        codebook: np.ndarray,\n","        normalized: bool = False,\n","        tfidf: bool = False\n","    ) -> np.ndarray:\n","        \"\"\"Get embeddings of image[idx] (image > descriptors > projection in codebook > frequencies vectors)\n","        :param idx: int, image index\n","        :param codebook: np.ndarray, visual vocabulary\n","        :param normalized: bool, if True, normalize embedding in scale [0, 1]\n","        \n","        :return: np.array, frequencies vector (can consider as embedding)\n","        \"\"\"\n","        _, img_descriptors = self._get_descriptors_one_img(idx)\n","        img_visual_words, distance = vq(img_descriptors, codebook)\n","        img_frequency_vector = np.histogram(\n","            img_visual_words, bins=codebook.shape[0], density=normalized\n","        )[0]\n","\n","        if tfidf:\n","            # TODO\n","            # self._tf_idf()\n","            # img_frequency_vector = img_frequency_vector * self.idf\n","            pass\n","        \n","        return img_frequency_vector\n","    # ------------------------ for inference ----------------------------\n","\n","    def _tf_idf(self):\n","        \"\"\"TODO: Reweight important features in codebook\"\"\"\n","        self.idf = 1\n","\n","        all_embeddings = []\n","        for i in range(len(self.df)):\n","            embedding = self.get_embedding(i)\n","            all_embeddings.append(embedding)\n","\n","        all_embeddings = np.stack(all_embeddings)\n","\n","        N = len(self.df)\n","        df = np.sum(all_embeddings > 0, axis=0)\n","        idf = np.log(N / df)\n","\n","        return idf\n","\n","    def _get_item(self, idx) -> tuple:\n","        \"\"\"Return pair (image(arr), label)\n","        :param idx: index of data\n","\n","        :return: tuple, (image: np.array, label)\n","        \"\"\"\n","        # get path of image\n","        GI_dir = {\"Lower GI\": \"lower-gi-tract\", \"Upper GI\": \"upper-gi-tract\"}\n","\n","        img = self.df[\"Video file\"][idx]\n","        gi_tract = GI_dir[self.df[\"Organ\"][idx]]\n","        classification = self.df[\"Classification\"][idx]\n","        finding = self.df[\"Finding\"][idx]\n","        path = f\"\"\"{self.root_dir}/{gi_tract}/{classification}/{finding}/{img}.jpg\"\"\"\n","        assert (\n","            os.path.exists(path) == True\n","        ), f\"{path} does not exist\"  # dir existance checking\n","\n","        # read image\n","        image = np.array(Image.open(path))\n","        label = self.labels.index(finding)\n","\n","        return image, label\n","    \n","    def _get_descriptors_one_img(self, idx, grayscale=True):\n","        \"\"\"Extracting descriptors for each image[idx]\n","        :param method: method to extract features e.g. ORB, SIFT, SURF, etc\n","        :param idx: image index\n","\n","        :return: descriptors\n","        :rtype: np.array\n","        \"\"\"\n","        # get image\n","        img, _ = self._get_item(idx)\n","        # preprocessing: convert to grayscale for efficient computing\n","        if len(img.shape) == 3 and grayscale:\n","            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","        # descriptors extracting\n","        img_keypoints, img_descriptors = self.extractor.detectAndCompute(img, None)\n","\n","        return img_keypoints, img_descriptors\n"]},{"cell_type":"markdown","metadata":{},"source":["# Pipeline"]},{"cell_type":"markdown","metadata":{},"source":["## 1. extracting descriptors"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T09:55:31.659589Z","iopub.status.busy":"2024-10-19T09:55:31.659166Z","iopub.status.idle":"2024-10-19T09:55:36.360971Z","shell.execute_reply":"2024-10-19T09:55:36.359758Z","shell.execute_reply.started":"2024-10-19T09:55:31.659550Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [00:02<00:00,  9.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["==================== Completely extracting descriptors ====================\n"]},{"data":{"text/plain":["(15912, 128)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["'''hyperparameters'''\n","method = 'sift'\n","sample_size = 20 # test\n","strongest_percent = 1\n","'''hyperparameters'''\n","\n","# ----- 1. extracting descriptors -------------\n","model = BagOfVisualWords(\n","        root_dir=root_dir,\n","        method=method\n","    )\n","descriptors_lake = model.extract_descriptors(sample_size=sample_size,\n","                                            strongest_percent=strongest_percent)\n","print('='*20, 'Completely extracting descriptors', '='*20)\n","\n","# =========== saving descriptors lake ===============\n","descriptors_lake_path = joblib.dump(descriptors_lake,\n","                                    f'{ckpt_path}/descriptors/id{s_id}-{sample_size}_img-{model.method}_extractor-{strongest_percent*100}%_strongest.pkl',\n","                                    compress=3)\n","# =================== free memory here ====================\n","del descriptors_lake\n","# =================== free memory here ====================\n","\n","# =================== load ================================\n","descriptors_lake = joblib.load(*descriptors_lake_path) # unpack list\n","descriptors_lake.shape"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Building codebook"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T09:55:36.363119Z","iopub.status.busy":"2024-10-19T09:55:36.362764Z","iopub.status.idle":"2024-10-19T09:55:38.383370Z","shell.execute_reply":"2024-10-19T09:55:38.381795Z","shell.execute_reply.started":"2024-10-19T09:55:36.363083Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Initializing: 100%|██████████| 10/10 [00:00<00:00, 15.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["==================== Completely building codebook ====================\n"]},{"data":{"text/plain":["(200, 128)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["'''hyperparameters'''\n","k = 200 # #cluster = vector size\n","cluster_algorithm='kmean'\n","'''hyperparameters'''\n","\n","# ------- 2. building visual vocabulary -----------\n","codebook = model.build_codebook(descriptors_lake=descriptors_lake,\n","                                    cluster_algorithm='kmean',\n","                                    k=200\n","                                )\n","print('='*20, 'Completely building codebook', '='*20)\n","\n","# =========== saving descriptors lake ===============\n","codebook_path = joblib.dump(codebook,\n","                            f'{ckpt_path}/codebook/id{s_id}-{cluster_algorithm}_cluster_algorithm-k={k}.pkl',\n","                            compress=3)\n","# =================== free memory here ====================\n","del descriptors_lake\n","del codebook\n","# =================== free memory here ====================\n","\n","# =================== load codebook ================================\n","codebook = joblib.load(*codebook_path) # unpack list\n","codebook.shape"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Classification"]},{"cell_type":"markdown","metadata":{},"source":["### Get embeddings\n","- img -> codebook -> embedding"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T10:13:25.669904Z","iopub.status.busy":"2024-10-19T10:13:25.669481Z","iopub.status.idle":"2024-10-19T10:13:25.675081Z","shell.execute_reply":"2024-10-19T10:13:25.673737Z","shell.execute_reply.started":"2024-10-19T10:13:25.669867Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<BarContainer object of 200 artists>"]},"execution_count":5,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["method='sift'\n","model = BagOfVisualWords(\n","        root_dir=root_dir,\n","        method=method\n","    )\n","\n","# =================== load codebook ================================\n","codebook = joblib.load(*codebook_path) # unpack list\n","\n","# ---------- hyperparams -----------------\n","normalized=False\n","# ---------- hyperparams -----------------\n","\n","embedding = model.get_embedding(0, codebook, normalized=normalized)\n","plt.bar(list(range(len(embedding))),embedding)"]},{"cell_type":"markdown","metadata":{},"source":["### Formating for classification"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T10:20:02.999111Z","iopub.status.busy":"2024-10-19T10:20:02.998669Z","iopub.status.idle":"2024-10-19T10:20:05.987239Z","shell.execute_reply":"2024-10-19T10:20:05.986241Z","shell.execute_reply.started":"2024-10-19T10:20:02.999069Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 10662/10662 [26:18<00:00,  6.76it/s]\n"]}],"source":["# ---------- hyperparams -----------------\n","normalized=False\n","# ---------- hyperparams -----------------\n","\n","headers = [f'feature{i}' for i in range(codebook.shape[0])]\n","embedding_df = pd.DataFrame(columns=headers)\n","labels = []\n","\n","# Embedding entire dataset\n","for idx in tqdm(range(len(model.df))):\n","    img, label = model._get_item(idx)\n","    embedding = model.get_embedding(idx, codebook, normalized=normalized)\n","    # Add a row to the DataFrame\n","    embedding_df.loc[len(embedding_df)] = embedding\n","    labels.append(label)\n","    # break\n","\n","embedding_df['label'] = pd.Series(labels, dtype='int')\n","\n","embedding_df.to_csv(f'{ckpt_path}/embedding_df/id{s_id}-{n_imgs}_img-normalized={normalized}.csv', index=False)\n","\n","# =================== free memory here ====================\n","del embedding_df\n","# =================== free memory here ===================="]},{"cell_type":"markdown","metadata":{},"source":["# Classification with embeddings"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T04:31:55.149002Z","iopub.status.busy":"2024-09-11T04:31:55.148366Z","iopub.status.idle":"2024-09-11T04:31:56.109387Z","shell.execute_reply":"2024-09-11T04:31:56.108194Z","shell.execute_reply.started":"2024-09-11T04:31:55.148954Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","# 1. Load dataset\n","df = pd.read_csv('/teamspace/studios/this_studio/checkpoints/embedding_df/id44-100_img-normalized=False.csv')"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["array([0])"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["np.unique(df['label'])"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T10:19:36.203567Z","iopub.status.busy":"2024-10-19T10:19:36.203113Z","iopub.status.idle":"2024-10-19T10:19:36.236848Z","shell.execute_reply":"2024-10-19T10:19:36.235139Z","shell.execute_reply.started":"2024-10-19T10:19:36.203524Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'train_test_split' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m200\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Step 3: Divide the dataset into training and testing sets (80% training, 20% testing)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Step 4: Train a basic model (Random Forest Classifier in this case)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"]}],"source":["# 2. Extract features, labels\n","X = df.iloc[:, 0:200]\n","y = df.iloc[:, 200]\n","\n","# Step 3: Divide the dataset into training and testing sets (80% training, 20% testing)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Step 4: Train a basic model (Random Forest Classifier in this case)\n","model = RandomForestClassifier(random_state=42)\n","model.fit(X_train, y_train)\n","\n","# Step 5: Predict on the test set\n","y_pred = model.predict(X_test)\n","\n","# Step 6: Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy * 100:.2f}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T04:32:20.303851Z","iopub.status.busy":"2024-09-11T04:32:20.303431Z"},"trusted":true},"outputs":[],"source":["# Step 7: Perform cross-validation\n","cv_scores = cross_val_score(model, X, y, cv=5)  # 5-fold cross-validation\n","print(f'Cross-validation Accuracy: {cv_scores.mean() * 100:.2f}%')\n"]},{"cell_type":"markdown","metadata":{},"source":["# Test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-08T15:45:33.205529Z","iopub.status.busy":"2024-09-08T15:45:33.204945Z","iopub.status.idle":"2024-09-08T15:45:33.524331Z","shell.execute_reply":"2024-09-08T15:45:33.523152Z","shell.execute_reply.started":"2024-09-08T15:45:33.205467Z"},"trusted":true},"outputs":[],"source":["\n","# =========== Sanity check =================================\n","# ====================== Unit tests =================================================\n","def test_attributes():\n","    assert model.df.shape == (10662, 4)  # dataframe\n","    assert len(model.labels) == 23  # #labels\n","\n","\n","# test _get_item method\n","def test_get_item():\n","    image, label = model._get_item(0)\n","    assert len(image.shape) == 3  # image is a 3-dimensional array (h, w, c)\n","    assert type(label) == int and 0 <= label <= 22  # label\n","\n","\n","# test _get_descriptors method\n","def test_get_descriptors():\n","    img_descriptors = model._get_descriptors(0)\n","    assert len(img_descriptors.shape) == 2\n","\n","\n","# test extract all descriptors process method\n","def test_extract_desciptors():\n","    # descriptors_lake = model.extract_descriptors() # ensure output is 2d\n","    assert len(model.descriptors_lake.shape) == 2, \"Invalid extracting process\"\n","    # assert len(model.sample_idx) == 1000, 'Invalid sampling'\n","\n","\n","# test build_codebook method\n","def test_build_codebook():\n","    assert model.codebook.shape == (model.k, 128), \"Invalid building codebook process\"\n","\n","\n","# test get_embedding method\n","def test_get_embedding():\n","    embedding = model.get_embedding(0)\n","    assert embedding.shape[0] == model.k\n","    \n","test_attributes()\n","test_get_item()\n","test_get_descriptors()\n","# test_extract_desciptors()\n","test_build_codebook()\n","test_get_embedding()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":1150130,"sourceId":1928154,"sourceType":"datasetVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
